{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvae import Encoder, Decoder, CVAE, BaselineNet\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "\n",
    "class CVAETrainer(nn.Module):\n",
    "    def __init__(self, data, b, train_test_split_ratio, state_dim, base_model_path, states):\n",
    "        super(CVAETrainer, self).__init__()\n",
    "        \n",
    "        self.b = b\n",
    "        self.train_test_split_ratio = train_test_split_ratio\n",
    "        self.states = states\n",
    "\n",
    "        states_dataset = TensorDataset(self.states)\n",
    "\n",
    "        train_size = int(self.train_test_split_ratio * len(states_dataset))\n",
    "        test_size = len(states_dataset) - train_size\n",
    "\n",
    "        train_dataset, test_dataset = random_split(states_dataset, [train_size, test_size])\n",
    "\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=b, shuffle=True)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=b, shuffle=True)\n",
    "\n",
    "        self.dataloaders = {'train':self.test_loader, 'val':self.test_loader}\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "\n",
    "        self.base_model_path = base_model_path\n",
    "    \n",
    "    def train_baseline(self, num_epochs, optimizer, criterion, baseline_model, early_stop_patience = 10, hidden1=128, hidden2=128):\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        baseline_model = baseline_model.to(device)\n",
    "        best_loss = np.inf\n",
    "        early_stop_count = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for phase in [\"train\", \"val\"]:\n",
    "                if phase == \"train\":\n",
    "                    baseline_model.train()\n",
    "                else:\n",
    "                    baseline_model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                num_preds = 0\n",
    "\n",
    "                bar = tqdm(\n",
    "                    self.dataloaders[phase], desc=\"NN Epoch {} {}\".format(epoch, phase).ljust(20)\n",
    "                )\n",
    "                for i, batch in enumerate(bar):\n",
    "                    x = batch.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == \"train\"):\n",
    "                        preds = baseline_model(x)\n",
    "                        loss = criterion(preds, x) / x.size(0)\n",
    "                        if phase == \"train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "                    num_preds += 1\n",
    "                    if i % 10 == 0:\n",
    "                        bar.set_postfix(\n",
    "                            loss=\"{:.2f}\".format(running_loss / num_preds),\n",
    "                            early_stop_count=early_stop_count,\n",
    "                        )\n",
    "\n",
    "                epoch_loss = running_loss / len(self.dataloaders[phase])\n",
    "                # deep copy the model\n",
    "                if phase == \"val\":\n",
    "                    if epoch_loss < best_loss:\n",
    "                        best_loss = epoch_loss\n",
    "                        best_model_wts = deepcopy(baseline_model.state_dict())\n",
    "                        early_stop_count = 0\n",
    "                    else:\n",
    "                        early_stop_count += 1\n",
    "\n",
    "            if early_stop_count >= early_stop_patience:\n",
    "                break\n",
    "\n",
    "        torch.save(baseline_model.state_dict(), f\"{self.base_model_path}/baseline.pth\")\n",
    "\n",
    "        return baseline_model\n",
    "\n",
    "\n",
    "    def train(self, num_epochs, optimizer, baseline_net, early_stop_patience, cvae_net, z_dim = 200, hidden1 = 500, hidden2 = 500, scheduler=None):\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        cvae_net = cvae_net.to(device)\n",
    "    \n",
    "        best_loss = np.inf\n",
    "        early_stop_count = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for phase in [\"train\", \"val\"]:\n",
    "                running_loss = 0.0\n",
    "                num_preds = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                bar = tqdm(\n",
    "                    self.dataloaders[phase],\n",
    "                    desc=\"CVAE Epoch {} {}\".format(epoch, phase).ljust(20),\n",
    "                )\n",
    "                for i, batch in enumerate(bar):\n",
    "                    x = batch.to(device)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        cvae_net.train()\n",
    "                        y_mean, y_std, z_mean_rec, z_std_rec, z_mean_prior, z_std_prior = cvae_net(x, x)\n",
    "                        loss = cvae_net.compute_loss(x, y_mean, y_std, z_mean_rec, z_std_rec, z_mean_prior, z_std_prior)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    else:\n",
    "                        cvae_net.eval()\n",
    "                        y_mean, y_std, z_mean_rec, z_std_rec, z_mean_prior, z_std_prior = cvae_net(x)\n",
    "                        loss = cvae_net.compute_loss(x, y_mean, y_std, z_mean_rec, z_std_rec, z_mean_prior, z_std_prior)\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss \n",
    "                    num_preds += 1\n",
    "                    if i % 10 == 0:\n",
    "                        bar.set_postfix(\n",
    "                            loss=\"{:.2f}\".format(running_loss / num_preds),\n",
    "                            early_stop_count=early_stop_count,\n",
    "                        )\n",
    "\n",
    "                epoch_loss = running_loss / len(self.dataloaders[phase])\n",
    "                # deep copy the model\n",
    "                if phase == \"val\":\n",
    "                    if epoch_loss < best_loss:\n",
    "                        best_loss = epoch_loss\n",
    "                        torch.save(cvae_net.state_dict(), f\"{self.base_model_path}/cvae.pth\")\n",
    "                        early_stop_count = 0\n",
    "                    else:\n",
    "                        early_stop_count += 1\n",
    "\n",
    "            if early_stop_count >= early_stop_patience:\n",
    "                break\n",
    "\n",
    "        return cvae_net\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file = \"D:\\IIT Madras\\Sem 7\\Advances in RL\\DA7400-Project\\HIGOC_framework\\Ant_maze_u-maze_noisy_multistart_False_multigoal_False_sparse.hdf5\"\n",
    "    trainer_obj = CVAETrainer(file, 32, 0.8, 111, \"HIGOC_framework/weights\", states)\n",
    "    baseline_model = BaselineNet(111, 128, 128)\n",
    "    optimizer = torch.optim.Adam(baseline_model.parameters(), 1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "    baseline_net = trainer_obj.train_baseline(100, optimizer, criterion, baseline_model)\n",
    "\n",
    "    cvae_model = CVAE(111, 200, 500, 500, baseline_net)\n",
    "    cvae_model = trainer_obj.train(100, optimizer, baseline_net, 10, cvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\I'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\I'\n",
      "C:\\Users\\kidam\\AppData\\Local\\Temp\\ipykernel_26012\\118813287.py:2: SyntaxWarning: invalid escape sequence '\\I'\n",
      "  with h5py.File(\"D:\\IIT Madras\\Sem 7\\Advances in RL\\DA7400-Project\\HIGOC_framework\\Ant_maze_u-maze_noisy_multistart_False_multigoal_False_sparse.hdf5\", 'r') as hdf:\n",
      "C:\\Users\\kidam\\AppData\\Local\\Temp\\ipykernel_26012\\118813287.py:2: SyntaxWarning: invalid escape sequence '\\I'\n",
      "  with h5py.File(\"D:\\IIT Madras\\Sem 7\\Advances in RL\\DA7400-Project\\HIGOC_framework\\Ant_maze_u-maze_noisy_multistart_False_multigoal_False_sparse.hdf5\", 'r') as hdf:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIIT Madras\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSem 7\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAdvances in RL\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDA7400-Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHIGOC_framework\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAnt_maze_u-maze_noisy_multistart_False_multigoal_False_sparse.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hdf:\n\u001b[1;32m----> 3\u001b[0m         states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtensor(hdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservations\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "with h5py.File(\"D:\\IIT Madras\\Sem 7\\Advances in RL\\DA7400-Project\\HIGOC_framework\\Ant_maze_u-maze_noisy_multistart_False_multigoal_False_sparse.hdf5\", 'r') as hdf:\n",
    "        states = torch.tensor(hdf['observations'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
